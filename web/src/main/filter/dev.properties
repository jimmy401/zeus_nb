#环境配置，用来标记环境，可以配合Environment使用
zeus.env=dev
zeus.loggingRoot=/data/applogs/zeus/log
#临时文件文件夹
zeus.tempWorkPath=/mnt/sdb1/zeus/temp
zeus.loggingLevel=debug
#默认worker的host组id
zeus.defaultWorkerGroup.id=1
#抢占master的host组id
zeus.preemptionMasterGroup.id=1

#任务执行文件夹，每次任务都会在此文件夹下新建一个临时文件夹
zeus.localdata.dir=/data/zeus/job_dir
#此处必须是hdfs路径，所有的上传附件都会存放在下面路径上
zeus.hdfsLibPath=/zeus/hdfs-upload-dir

#环境配置，如果是在一个集群中，需要配置城同一个名称
zeus.schedule.group=online
#Scheduler 与 Worker 通信的端口
zeus.connect.port=9887
#hadoop jobtracker地址，填写ip+port 或者 domain+port
zeus.jobtracker=

#zk配置非必选，可以为空，此处的zk是用来通知任务的成功失败事件的
zeus.zookeeper.host=

#hadoop 配置文件路径
hadoop.home=/usr/lib/hadoop
hadoop.conf.dir=/etc/hadoop/conf

#hive 配置文件路径
hive.home=/usr/lib/hive
hive.conf.dir=/etc/hive/conf
hive.beeline.shell=beeline -u 'jdbc:hive2://10.200.60.114:10003/default;principal=hive/ddp-cm.cmdmp.com@CMDMP.COM'

#不需要dos2unix转换的文件类型
dos2unix.exclude.file=jar

kerberos.auth=true
kerberos.user=hadoop

####
#db.url=jdbc:mysql://192.168.199.36:3306/zeus_lky1?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true
#db.username=root
#db.password=zq

#####
deployenv=qa
zkserver=192.168.199.13:2181,192.168.199.14:2181,192.168.199.15:2181

ds.zeus-m1-write.jdbc.url=jdbc:mysql://localhost:3306/zeus?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true&amp;useSSL=false
ds.zeus-m1-write.jdbc.username=root
ds.zeus-m1-write.jdbc.password=root